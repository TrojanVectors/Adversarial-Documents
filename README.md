# Adversarial Documents Examples

## Summary

This repository demonstrates indirect prompt injection attacks on real-world RAG (Retrieval-Augmented Generation) chatbots, promoting secure AI development and awareness.

## Overview

Indirect prompt injection attacks manipulate AI applications by injecting carefully crafted content into the chatbot's knowledge base (vector databases), influencing its responses. This repository provides concrete examples and steps to reproduce these attacks, helping developers and researchers understand and mitigate these vulnerabilities.

## Contents

- **NotionAI:** An example of an indirect prompt injection attack on Notion AI, demonstrating the potential impact on its responses. We informed Notion about this vulnerability a month ago.
- **Other chatbot examples:** We have identified similar vulnerabilities in multiple other public-facing RAG chatbots and are in the process of informing those companies. Once disclosed, we will provide respective examples in this repository.

## Goals

- Educate developers, researchers, and users about indirect prompt injection attacks and their potential effects.
- Encourage secure AI development and the implementation of mitigations against these attacks.
- Foster a community-driven approach to identifying and addressing AI vulnerabilities.

## Important Notes

- This repository is for educational purposes only. Please do not use the techniques demonstrated here to manipulate or deceive others.
- The examples provided are intended to illustrate the potential risks and limitations of AI applications, not to exploit or harm specific chatbots or their users.

## Security Importance

Addressing these vulnerabilities is crucial to ensure the security and trustworthiness of AI applications. Failing to do so can have significant consequences, including 
- Manipulated responses
- Loss of user trust
- Compromised privacy and security

## Resources

- Trojan Vectors Website - TrojanVectors.com

## Get In Touch

- Schedule a [call](https://cal.com/sachdh/30min) with us 
- Send an email to contact@trojanvectors.com to discuss how to secure your AI applications and address potential vulnerabilities.
